{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "jupyter: python3\n",
        "---\n",
        "\n",
        "**CSI 4506 Introduction à l'intelligence artificielle** <br/>\n",
        "*Devoir 2 : Santé des animaux de compagnie extra-terrestres, apprentissage automatique*\n",
        "\n",
        "# Identification\n",
        "\n",
        "Nom : <br/>\n",
        "Numéro d'étudiant :\n",
        "\n",
        "## 1. Données\n",
        "\n",
        "Le devoir 2 inclut deux versions du même jeu de données : l'une contenant des valeurs manquantes et l'autre sans. La version avec des valeurs manquantes a été dérivée du jeu de données complet :\n",
        "\n",
        "- [github.com/turcotte/csi4106-f25/tree/main/assignments-data/a2](https://github.com/turcotte/csi4106-f25/tree/main/assignments-data/a2)\n",
        "\n",
        "Dans votre cahier, vous pouvez accéder et lire les données directement depuis ce dépôt GitHub.\n",
        "\n",
        "- [alien_pet_health-realism-clean.csv](https://raw.githubusercontent.com/turcotte/csi4106-f25/main/assignments-data/a2/alien_pet_health-realism-clean.csv)\n",
        "- [alien_pet_health-realism-clean-missing.csv](https://raw.githubusercontent.com/turcotte/csi4106-f25/main/assignments-data/a2/alien_pet_health-realism-clean-missing.csv)\n",
        "\n",
        "## 2. Tâches\n",
        "\n",
        "Les tâches sont organisées dans un ordre particulier pour maintenir la concision et la clarté. Il y a de la flexibilité dans la structure de votre code. Améliorez son organisation en ajoutant des cellules de code si nécessaire. Vous pouvez modifier l'ordre des tâches ; par exemple, vous pourriez choisir de définir des méthodes auxiliaires au début. Néanmoins, il est crucial que l'assistant d'enseignement puisse identifier facilement les segments de code associés à chaque tâche.\n",
        "\n",
        "(1) **Charger le jeu de données**\n",
        "\n",
        "- Lire le fichier CSV sans données manquantes (`alien_pet_health-realism-clean.csv`).\n",
        "\n",
        "- Afficher la forme (*shape*) des données, ainsi que les cinq premières lignes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(2) **Analyse de la distribution des attributs** :\n",
        "\n",
        "- Pour identifier la méthode de codage appropriée pour chaque attribut, il est utile d'examiner leurs distributions à l'aide d'outils de visualisation tels que les histogrammes. Cette analyse permettra de prendre des décisions basées sur les données concernant les stratégies de codage appropriées."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(3) **Données d'entraînement et cible** :\n",
        "\n",
        "- Pour chaque jeu de données, définir des variables Python, telles que `X` pour les données et `y` pour la classe cible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(4) **Division des données** :\n",
        "\n",
        "- Diviser le jeu de données en ensembles d'entraînement (80%) et de test (20%) en utilisant la méthode de la réserve (*hold out*).\n",
        "\n",
        "- S'assurer que cette division se produit avant tout prétraitement pour éviter toute fuite de données."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Prétraitement des données\n",
        "\n",
        "(5) **Codage des variables catégorielles** :\n",
        "\n",
        "- Transformer toutes les variables catégoriques en utilisant des techniques de codage appropriées disponibles dans [sklearn.preprocessing](https://scikit-learn.org/stable/api/sklearn.preprocessing.html). Pour plus de conseils, consultez la section [Prétraitement des Données](https://scikit-learn.org/stable/modules/preprocessing.html) du guide de l'utilisateur. Fournir une justification pour la méthode de codage sélectionnée."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(6) **Normalisation/standardisation des attributs numériques** :\n",
        "\n",
        "- Normaliser ou standardiser les attributs numériques si nécessaire. Décrire la technique utilisée (par exemple, échelle Min-Max, StandardScaler) et expliquer pourquoi elle convient à ce jeu de données.\n",
        "\n",
        "- S'assurer que cette technique est appliquée uniquement aux données d'entraînement, avec la même transformation appliquée ultérieurement aux données de test sans l'ajuster sur elles."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Développement et évaluation du modèle\n",
        "\n",
        "(7) **Développement de modèles** :\n",
        "\n",
        "- Implémenter les modèles d'apprentissage automatique couverts en classe : K-Nearest Neighbors (KNN), Arbres de Décision, et Régression Logistique, ainsi que la Forêt Aléatoire. Utiliser les paramètres par défaut de scikit-learn comme base pour l'entraînement de chaque modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "(8) **Évaluation des modèles** :\n",
        "\n",
        "- Utiliser la validation croisée pour évaluer chaque modèle, en justifiant votre choix du nombre de plis.\n",
        "\n",
        "- Évaluer les modèles en utilisant des métriques telles que la précision, le rappel, et le score F1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Optimisation des hyperparamètres\n",
        "\n",
        "(9) **Exploration et évaluation des performances :**\n",
        "\n",
        "- Étudier l'impact de la variation des valeurs des hyperparamètres sur les performances de chaque modèle.\n",
        "\n",
        "- Pour chaque modèle, s'assurer de faire varier au moins les hyperparamètres suivants :\n",
        "\n",
        "    - [KNeighborsClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.neighbors.KNeighborsClassifier.html):`n_neighbors` et `weights`.\n",
        "\n",
        "    - [DecisionTreeClassifier](https://scikit-learn.org/dev/modules/generated/sklearn.tree.DecisionTreeClassifier.html):`criterion` et `max_depth`.\n",
        "  \n",
        "    - [LogisticRegression](https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html):`penalty`, `max_iter`, et `tol`.\n",
        "\n",
        "    - [RandomForestClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html):`n_estimators`, `max_depth`.\n",
        "\n",
        "- Utiliser une stratégie de recherche en grille ou utiliser les méthodes intégrées de scikit-learn pour évaluer minutieusement toutes les combinaisons de valeurs d'hyperparamètres. La validation croisée doit être utilisée pour évaluer chaque combinaison.\n",
        "\n",
        "- Quantifier la performance de chaque configuration d'hyperparamètres en utilisant la précision, le rappel, et le score F1 comme métriques. Rapporter à la fois la moyenne et l'écart-type.\n",
        "\n",
        "- Présenter les résultats sous un format tabulaire ou graphique (par exemple, graphiques en ligne, graphiques à barres) pour démontrer efficacement l'influence des variations d'hyperparamètres sur les performances du modèle.\n",
        "\n",
        "- Spécifier les valeurs par défaut pour chaque hyperparamètre testé.\n",
        "\n",
        "- Analyser les résultats et offrir des perspectives sur quelles configurations d'hyperparamètres ont atteint des performances optimales pour chaque modèle."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Analyse des résultats\n",
        "\n",
        "(10) **Comparaison des modèles** :\n",
        "\n",
        "- Comparer les résultats obtenus pour chaque modèle.\n",
        "\n",
        "- Discuter des différences observées dans les performances des modèles, en fournissant des explications potentielles. Considérer des aspects tels que la complexité du modèle, le déséquilibre des données, le surapprentissage, et l'impact de l'ajustement des paramètres sur les résultats globaux.\n",
        "\n",
        "- Fournir des recommandations sur le(s) modèle(s) à choisir pour cette tâche et justifier vos choix basés sur les résultats de l'analyse.\n",
        "\n",
        "- Entraîner le(s) modèle(s) recommandé(s) en utilisant les valeurs de paramètres optimales identifiées lors de l'étape d'optimisation des paramètres. Appliquer ensuite le modèle entraîné aux données de test. Documenter vos observations de manière exhaustive. Évaluer spécifiquement si les résultats dérivés de la validation croisée sont cohérents avec ceux obtenus à partir de l'ensemble de test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Gestion des données manquantes\n",
        "\n",
        "(11) **Évaluer comment les valeurs manquantes affectent les performances du modèle :**\n",
        "\n",
        "- Lire le fichier CSV avec des données manquantes (`alien_pet_health-realism-clean-missing.csv`).\n",
        "\n",
        "- Présenter une brève analyse des données manquantes dans le jeu de données en rapportant à la fois le nombre et le pourcentage de valeurs manquantes pour chaque colonne ainsi que pour l'ensemble du jeu de données. Fournir également une répartition du nombre et de la proportion de lignes classées par absence de données manquantes, et celles contenant une, deux ou plus de valeurs manquantes.\n",
        "\n",
        "- Appliquer une stratégie d'imputation simple (par exemple, médiane pour les numériques, et la plus fréquente pour les catégorielles).\n",
        "\n",
        "- Standardiser et normaliser les attributs numériques, et encoder les données catégorielles en utilisant les méthodes de prétraitement des données précédemment décrites.\n",
        "\n",
        "- Utiliser la validation croisée pour évaluer l'efficacité de la stratégie d'imputation des données, étant donné que la combinaison optimale d'algorithmes d'apprentissage et d'hyperparamètres a déjà été déterminée.\n",
        "\n",
        "- Discuter des différences observées dans les performances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explicabilité du modèle (Optionnel)\n",
        "\n",
        "L'explicabilité dans l'apprentissage automatique se réfère à la capacité de comprendre et d'interpréter les décisions prises par un modèle. Les valeurs SHAP (SHapley Additive exPlanations) fournissent une mesure unifiée pour expliquer la contribution de chaque attribut à la prédiction du modèle, offrant des perspectives sur comment et pourquoi un modèle fait des prédictions spécifiques, renforçant ainsi la transparence et la confiance dans les modèles complexes.\n",
        "\n",
        "Cette question est optionnelle. Vous pouvez choisir de l'aborder si vous souhaitez explorer le sujet ou si vous cherchez à obtenir des points supplémentaires.\n",
        "\n",
        "(12) **Importance des attributs :**\n",
        "\n",
        "- Avec les hyperparamètres déjà optimisés, calculer les valeurs [SHAP](https://shap.readthedocs.io/en/latest/index.html) (SHapley Additive exPlanations) pour évaluer l'importance des attributs pour les modèles K-Nearest Neighbors (KNN), Arbres de Décision, et Régression Logistique. Pour chaque modèle, produire un graphique récapitulatif qui identifie et met en avant les cinq attributs les plus influents utilisées lors de l'étape de classification."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# Code Python"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Références\n",
        "\n",
        "# Ressources\n",
        "\n",
        "Si vous utilisez une assistance IA, il est essentiel de documenter méticuleusement toutes les interactions. Votre rapport doit spécifier les outils et leurs versions, accompagnés d'une transcription complète de ces interactions. La plupart des plateformes d'IA enregistrent automatiquement les conversations, il est donc conseillé de lancer une nouvelle conversation spécifiquement pour le travail et d'utiliser constamment ce fil tout au long de votre travail. Assurez-vous que cette conversation reste exclusivement centrée sur le travail. Inclure la transcription de cette conversation."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3 (ipykernel)",
      "path": "/Users/turcotte/opt/micromamba/envs/ai/share/jupyter/kernels/python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}